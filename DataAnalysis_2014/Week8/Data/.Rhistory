datafile<-read.csv("~/Desktop/data.csv")
setwd("C:/Users/bkamble3/Desktop")
datafile<-read.csv("data.csv")
head(datafile)
datafile$starttime<-as.POSIXct(datafile$starttime, format="%Y-%m-%d %H:%M:%S")
datafile$stoptime<-as.POSIXct(datafile$stoptime, format="%Y-%m-%d %H:%M:%S")
diffs<-datafile$stoptime-datafile$starttime
AvgTime<-mean(diffs[diffs!=0])
head(datafile)
install.packages("plyr")
head(datafile)
datafile2<-arrange(datafile,bikeid,stoptime)
library(plyr)
datafile2<-arrange(datafile,bikeid,stoptime)
head (datafile2)
webdata<-"http://rci.rutgers.edu/~rwomack/UNRATE.csv"
webdata2<-"http://rci.rutgers.edu/~rwomack/CPIAUCSL.csv"
Unemployment<-read.csv(webdata, row.names=1)
Urate<-ts(Unemployment$VALUE, start=c(1948,1), freq=12)
Inflation<-read.csv(webdata2, row.names=1)
Irate<-ts((Inflation$VALUE), start=c(1948,1), freq=12)
Urate.July<-window(Urate, start=c(1980,7),freq=TRUE)
time(Urate)
plot(Urate)
abline(reg=lm(Urate~time(Urate)))
decompose(Urate)
plot(decompose(Urate))
plot(Irate,Urate)
plot(decompose(Urate))
plot(Irate,Urate)
ts.plot(Irate,Urate, col=c("blue","red"))
ts.plot(Irate,Urate, col=c("blue","red"))
acf(Urate)
acf(AP)
ts.union(Urate,AP)
acf(Urate)
acf(AP)
AP<-AirPassengers
data(AirPassengers)
AP<-AirPassengers
class(AP)
start(AP)
end(AP)
frequency(AP)
summary(AP)
plot(AP)
cycle(AP)
aggregate(AP)
aggregate(AP, FUN=mean)
plot(aggregate(AP))
boxplot(AP~cycle(AP))
AP.hw <- HoltWinters(AP)
plot(AP.hw)
AP.predict<-predict(AP.hw, n.ahead=10*12)
ts.plot(AP, AP.predict, lty=1:2)
UR.hw <- HoltWinters(Urate, seasonal="additive")
UR.predict<-predict(UR.hw, n.ahead=10*12)
ts.plot(Urate, UR.predict, lty=1:2)
install.packages("prob")
install.packages("SDMTools")
data(sunspots)
head(sunspots)
sunspots
sample.mean <- mean(sunspots)
sample.sd <- sd(sunspots)
n <- length(sunspots)
n
mu_0 <- 50
t.stat <- (sample.mean - mu_0)/(sample.sd/sqrt(n))
t.stat
p.value <- pnorm(-t.stat, 0, 1) + 1 - pnorm(t.stat, 0, 1)
p.value
p.value <- 1 - pnorm(t.stat, 0, 1)
p.value
##  H_A:  mu less than 51.25
p.value <- pnorm(t.stat, 0, 1)
p.value
t.test(sunspots, mu=mu_0, alternative = "two.sided")
t.test(sunspots, mu=mu_0, alternative = "greater")
t.test(sunspots, mu=mu_0, alternative = "less")
aa <- rbinom(100, 1, .6)
z.stat <- (mean(aa) - 0.5)/sqrt(0.5*(1 - 0.5)/100)
z.stat
pnorm(-z.stat) + 1 - pnorm(z.stat)
##  Either way, we compare our p-value to the level that we set beforehand for
xx1 <- rnorm(10, mean = 4, sd = 5)
xx2 <- rnorm(20, mean = 5, sd = 5)
t.test(xx1, xx2, alternative = "two.sided", var.equal = TRUE)
##  We can also see what happens when we don't assume equal variances:
t.test(xx1, xx2, alternative = "two.sided", var.equal = FALSE)
##  Or, we could test a one-sided hypothesis:
t.test(xx1, xx2, alternative = "less", var.equal = TRUE)
t.test(xx1, xx2, alternative = "greater", var.equal = TRUE)
t.test(xx1, xx2, mu = 1, alternative = "two.sided", var.equal = TRUE)
sample.mean
sample.sd
weatherdata<-read.table(file = "mead_2013.txt", header=TRUE, sep = "")
setwd("R:/bkamble/V1.0/R/download/Week8/Data")
weatherdata<-read.table(file = "mead_2013.txt", header=TRUE, sep = "")
X<-weatherdata$T.High
mean(X)
X
head(weatherdata)
X<-weatherdata$THigh
mean(X)
sd(X)
sample.sd
Temp<-weatherdata$THigh
data(Temp)
sample.mean <- mean(Temp)
sample.sd <- sd(Temp)
n <- length(Temp)
mu_0 <- 50
t.stat <- (sample.mean - mu_0)/(sample.sd/sqrt(n))
t.stat
p.value <- pnorm(-t.stat, 0, 1) + 1 - pnorm(t.stat, 0, 1)
p.value
# H_A : mu greater than 51.25
p.value <- 1 - pnorm(t.stat, 0, 1)
p.value
p.value <- pnorm(t.stat, 0, 1)
p.value
t.test(Temp, mu=mu_0, alternative = "two.sided")
t.test(Temp, mu=mu_0, alternative = "greater")
t.test(Temp, mu=mu_0, alternative = "less")
# For proportions, the approach is slightly different because you don't have
# to estimate the variance of the data; the variance is a function of the
# null hypothesis.
aa <- rbinom(100, 1, .6)
# Let's test the hypothesis that pi = .5 against the alternative that pi is not
# equal to 0.5:
z.stat <- (mean(aa) - 0.5)/sqrt(0.5*(1 - 0.5)/100)
z.stat
weatherdata<-read.table(file = "mead_2013.txt", header=TRUE, sep = "")
Temp<-weatherdata$THigh
sample.mean <- mean(Temp)
sample.sd <- sd(Temp)
n <- length(Temp)
sample.mean
mu_0 <- 80
t.stat <- (sample.mean - mu_0)/(sample.sd/sqrt(n))
t.stat
p.value <- pnorm(-t.stat, 0, 1) + 1 - pnorm(t.stat, 0, 1)
p.value
# H_A : mu greater than 51.25
p.value <- 1 - pnorm(t.stat, 0, 1)
p.value
# H_A:  mu less than 51.25
p.value <- pnorm(t.stat, 0, 1)
p.value
counts <- c (18 ,17 ,15 ,20 ,10 ,20 ,25 ,13 ,12)
outcome <- gl (3 ,1 ,9)
treatment <- gl (3 ,3)
4 print ( d . AD <-data . frame ( treatment,outcome, counts ) )
print ( d . AD <-data . frame ( treatment,outcome, counts ) )
print ( d.AD <-data.frame ( treatment,outcome, counts ) )
contin . table <-xtabs ( counts ~ treatment + outcome )
contin.table <-xtabs ( counts ~ treatment + outcome )
mosaicplot ( contin.table , main =" Mosaic Plot ")
dimnames ( contin.table )$ outcome <-c("Out_1","Out_2","Out_3")
dimnames ( contin.table )$ treatment <-c(" Treat _1"," Treat _2"," Treat _3")
dotchart ( contin.table , main ="Dot Chart ")
dotchart ( contin.table , main ="Dot Chart ", col="red")
Myglm <- glm(counts ~ outcome + treatment,family = poisson () )
anova(Myglm)
summary(Myglm)
anova(Myglm, test="Chisq")
install.packages("faraway")
library (faraway)
data (bliss)
bliss
weatherdata<-read.table(file = "Insecticide.txt", header=TRUE, sep = "")
Insecticidedata<-read.table(file = "Insecticide.txt", header=TRUE, sep = "")
head(Insecticidedata)
attach(Insecticidedata)
survival <-(alive/( alive + dead ) )
bliss <-data.frame ( bliss , survival )
plot ( survival ~conc , main =" Insecticide ")
MyLogistic <-glm ( cbind ( dead , alive )~conc , family = binomial , data = bliss )
summary ( MyLogistic )
survival <-(alive/( alive + dead ) )
MyData <-data.frame ( Insecticidedata , survival )
plot ( survival ~conc , main =" Insecticide ")
MyLogistic <-glm ( cbind ( dead , alive )~conc , family = binomial , data = MyData )
summary ( MyLogistic )
MyProbit <-glm ( cbind ( dead , alive )~conc , family = binomial (link = probit ) ,data = MyData )
summary(MyProbit)
modcloglog <-glm ( cbind ( dead , alive )~conc , family = binomial ( link = cloglog ) ,data = MyData )
summary(modcloglog)
cbind ( fitted ( MyLogistic ) ,fitted ( MyProbit ) ,fitted ( modcloglog ) )
head(Insecticidedata)
p <- read.csv("http://www.ats.ucla.edu/stat/data/poisson_sim.csv")
p
p <- within(p, {
prog <- factor(prog, levels=1:3, labels=c("General", "Academic", "Vocational"))
id <- factor(id)
})
p
MyLogistic2 <- predict(MyLogistic, type="response")
MyLogistic2
plot(cbind ( fitted ( MyLogistic ) ,fitted ( MyProbit ) ,fitted ( modcloglog ) ))
cbind ( fitted ( MyLogistic ) ,fitted ( MyProbit ) ,fitted ( modcloglog ) )
MyPredict<-cbind ( fitted ( MyLogistic ) ,fitted ( MyProbit ) ,fitted ( modcloglog ) )
plot(MyPredict)
plot(MyPredict$1)
head(MyPredict)
head(MyPredict[,1])
head(MyPredict[,2])
plot(MyPredict[,2])
plot(MyPredict[,3])
plot(MyPredict[,1])
pairs(MyPredict)
MyLogistic <-glm ( cbind ( dead , alive )~conc , family = binomial (link = logit ) , data = MyData )
summary ( MyLogistic )
print (data.frame ( treatment,outcome, counts ) )
contin.table <-xtabs ( counts ~ treatment + outcome )
mosaicplot ( contin.table , main =" Mosaic Plot ")
dimnames ( contin.table )$ outcome <-c("Out_1","Out_2","Out_3")
dimnames ( contin.table )$ treatment <-c(" Treat _1"," Treat _2"," Treat _3")
dotchart ( contin.table , main ="Dot Chart ")
#Poisson Regression
#Fitting a GLM
Myglm <- glm(counts ~ outcome + treatment,family = poisson () )
anova(Myglm)
summary(Myglm)
anova(Myglm, test="Chisq")
summary(Myglm)
summary(Myglm,correlation=TRUE)
MyPredict
MyPredict<-cbind ( predict ( MyLogistic ) ,predict ( MyProbit ) ,predict ( modcloglog ) )
MyPredict
MyFitted<-cbind ( fitted ( MyLogistic ) ,fitted ( MyProbit ) ,fitted ( modcloglog ) )
MyFitted-MyPredict
survival
plot ( survival ~conc , main =" Insecticide ")
MyLogistic <-glm ( cbind ( dead , alive )~conc , family = binomial (link = logit ) , data = MyData )
summary ( MyLogistic )
summary ( MyLogistic, correlation=TRUE)
Categoricaldata<-read.table(file = "Categorical.txt", header=TRUE, sep = "")
dimnames(Categoricaldata)
Categoricaldata<-read.table(file = "Categorical.txt", header=TRUE, sep = "")
dimnames(Categoricaldata)
Myglm = glm(cbind(Admit,Reject) ~ gender * dept, family=binomial(logit), data=Categoricaldata)
anova(glm.out, test="Chisq")
anova(Myglm, test="Chisq")
options(show.signif.stars=F)         # turn off significance stars (optional)
anova(Myglm, test="Chisq")
summary(Myglm)
exp(-1.0521)
exp(-2.7013)
#summer temparture at any location
mean=80
sd=10
lb=60
ub=100
data <- seq(-4,4,length=100)*sd + mean
hx <- dnorm(data,mean,sd)
plot(data, hx, type="n", xlab="Temperature Values", ylab="",
main="Normal Distribution", axes=FALSE)
i <- data>= lb & data <= ub
lines(data, hx)
polygon(c(lb,data[i],ub), c(0,hx[i],0), col="red")
area <- pnorm(ub, mean, sd) - pnorm(lb, mean, sd)
result <- paste("P(",lb,"< Temp <",ub,") =",
signif(area, digits=3))
mtext(result,3)
axis(1, at=seq(40, 160, 20), pos=0)
#summer temparture at any location
mean=80
sd=10
lb=60
ub=100
data <- seq(-4,4,length=100)*sd + mean
hx <- dnorm(data,mean,sd)
plot(data, hx, type="n", xlab="Temperature Values", ylab="",
main="Normal Distribution", axes=FALSE)
i <- data>= lb & data <= ub
lines(data, hx)
polygon(c(lb,data[i],ub), c(0,hx[i],0), col="red")
area <- pnorm(ub, mean, sd) - pnorm(lb, mean, sd)
result <- paste("P(",lb,"< Temp <",ub,") =",
signif(area, digits=3))
mtext(result,3)
axis(1, at=seq(40, 160, 20), pos=0)
x <- seq(-4, 4, length=100)
hx <- dnorm(x)
degf <- c(1, 3, 8, 30)
colors <- c("red", "blue", "darkgreen", "gold", "black")
labels <- c("df=1", "df=3", "df=8", "df=30", "normal")
plot(x, hx, type="l", lty=2, xlab="x value",
ylab="Density", main="Comparison of t Distributions")
for (i in 1:4){
lines(x, dt(x,degf[i]), lwd=2, col=colors[i])
}
legend("topright", inset=.05, title="Distributions",
labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)
mean=80
sd=10
lb=60
ub=100
data <- seq(-4,4,length=100)*sd + mean
hx <- dnorm(data,mean,sd)
plot(data, hx, type="n", xlab="Temperature Values", ylab="",
main="Normal Distribution", axes=FALSE)
i <- data>= lb & data <= ub
lines(data, hx)
polygon(c(lb,data[i],ub), c(0,hx[i],0), col="red")
area <- pnorm(ub, mean, sd) - pnorm(lb, mean, sd)
result <- paste("P(",lb,"< Temp <",ub,") =",
signif(area, digits=3))
mtext(result,3)
axis(1, at=seq(40, 160, 20), pos=0)
axis(1, at=seq(40, 160, 10), pos=0)
hx <- dnorm(data,mean,sd)
plot(data, hx, type="n", xlab="Temperature Values", ylab="",
main="Normal Distribution", axes=FALSE)
i <- data>= lb & data <= ub
lines(data, hx)
polygon(c(lb,data[i],ub), c(0,hx[i],0), col="green")
area <- pnorm(ub, mean, sd) - pnorm(lb, mean, sd)
result <- paste("P(",lb,"< Temp <",ub,") =",
signif(area, digits=3))
mtext(result,3)
axis(1, at=seq(40, 160, 10), pos=0)
ub=90
data <- seq(-4,4,length=100)*sd + mean
hx <- dnorm(data,mean,sd)
plot(data, hx, type="n", xlab="Temperature Values", ylab="",
main="Normal Distribution", axes=FALSE)
i <- data>= lb & data <= ub
lines(data, hx)
polygon(c(lb,data[i],ub), c(0,hx[i],0), col="green")
area <- pnorm(ub, mean, sd) - pnorm(lb, mean, sd)
result <- paste("P(",lb,"< Temp <",ub,") =",
signif(area, digits=3))
mtext(result,3)
axis(1, at=seq(40, 160, 10), pos=0)
x <- sort(rnorm(100,0,0.5))
h <- hist(x,plot=FALSE)
dens1 <-  h$counts/sum(h$counts)
dens2 <- dnorm(x,0,0.5)
hist(x,probability=TRUE,breaks="fd",ylim=c(0,1))
lines(h$mids,dens1,col="red")
lines(x,dens2,col="darkgreen")
cdf <- cumsum(dens$y * diff(dens$x[1:2]))
energy <- rnorm(100)
dens <- density(energy)
sum(dens$y)*diff(dens$x[1:2])
hist(energy,probability=TRUE) #Use the probability=TRUE option of hist or the function density() (or both)
lines(density(energy),col="red")
x <- sample(letters[1:4],1000,replace=TRUE)
prop.table(table(x))
cdf <- cumsum(dens$y * diff(dens$x[1:2]))
cdf <- cdf / max(cdf) # to correct for the rounding errors
plot(dens$x,cdf,type="l")
hist(x,probability=TRUE,breaks="fd",ylim=c(0,1))
x <- sort(rnorm(100,0,0.5))
h <- hist(x,plot=FALSE)
dens1 <-  h$counts/sum(h$counts)
dens2 <- dnorm(x,0,0.5)
hist(x,probability=TRUE,breaks="fd",ylim=c(0,1))
lines(h$mids,dens1,col="red")
lines(x,dens2,col="darkgreen")
#The cumulative distribution function
x <- sort(rnorm(100,0,0.5))
h <- hist(x,plot=FALSE)
dens1 <-  h$counts/sum(h$counts)
dens2 <- dnorm(x,0,0.5)
hist(x,probability=TRUE,breaks="fd",ylim=c(0,1))
lines(h$mids,dens1,col="red")
lines(x,dens2,col="darkgreen")
hist(x,probability=TRUE,breaks="fd",ylim=c(0,1), xlim=c(-1.5,1.5))
lines(h$mids,dens1,col="red")
lines(x,dens2,col="darkgreen")
hist(x,probability=TRUE,breaks="fd",ylim=c(0,1), xlim=c(-1,1))
lines(h$mids,dens1,col="red")
lines(x,dens2,col="darkgreen")
hist(x,probability=TRUE,breaks="fd",ylim=c(0,1), xlim=c(-1.5,1.5))
lines(h$mids,dens1,col="red")
lines(x,dens2,col="darkgreen")
#The cumulative distribution function
energy <- rnorm(100)
dens <- density(energy)
sum(dens$y)*diff(dens$x[1:2])
hist(energy,probability=TRUE) #Use the probability=TRUE option of hist or the function density() (or both)
lines(density(energy),col="red")
x <- sample(letters[1:4],1000,replace=TRUE)
prop.table(table(x))
par(mfrow=c(2,2))                                   # Create a 2x2 plotting area
plot(x, dunif(x,min=2,max=4), main="Uniform",       # Plot a uniform density
type='l', ylim=ylim)
plot(x, dnorm(x,mean=3,sd=1), main="Normal",        # Plot a Normal density
type='l', ylim=ylim)
plot(x, dunif(x,min=2,max=4), main="Uniform",       # Plot a uniform density
type='l', ylim=c(0, 0.6))
x <- seq(-4, 4, length=100)
plot(x, dunif(x,min=2,max=4), main="Uniform",       # Plot a uniform density
type='l', ylim=c(0, 0.6))
x <- seq(from=0, to=6, length.out=100)
par(mfrow=c(2,2))                                   # Create a 2x2 plotting area
plot(x, dunif(x,min=2,max=4), main="Uniform",       # Plot a uniform density
type='l', ylim=c(0, 0.6))
plot(x, dnorm(x,mean=3,sd=1), main="Normal",        # Plot a Normal density
type='l', ylim=c(0, 0.6))
plot(x, dexp(x,rate=1/2), main="Exponential",       # Plot an exponential density
type='l', ylim=c(0, 0.6))
plot(x, dgamma(x,shape=2,rate=1), main="Gamma",     # Plot a gamma density
type='l', ylim=c(0, 0.6))
x <- seq(from=-3, to=+3, length.out=100)
y <- dnorm(x)
plot(x, y, main="Standard Normal Distribution", type='l',
ylab="Density", xlab="Quantile")
abline(h=0)
region.x <- x[1 <= x & x <= 2]
region.y <- y[1 <= x & x <= 2]
region.x <- c(region.x[1], region.x, tail(region.x,1))
region.y <- c(          0, region.y,                0)
polygon((region.x, region.y, density=10))
polygon(region.x, region.y, density=10)
par(mfrow=c(1,1))
plot(x, dunif(x,min=2,max=4), main="Uniform",       # Plot a uniform density
type='l', ylim=c(0, 0.6))
x <- seq(-4, 4, length=100)
hx <- dnorm(x)
degf <- c(1, 3, 8, 30)
colors <- c("red", "blue", "darkgreen", "gold", "black")
labels <- c("df=1", "df=3", "df=8", "df=30", "normal")
plot(x, hx, type="l", lty=2, xlab="x value",
ylab="Density", main="Comparison of t Distributions")
for (i in 1:4){
lines(x, dt(x,degf[i]), lwd=2, col=colors[i])
}
legend("topright", inset=.05, title="Distributions",labels, lwd=2, lty=c(1, 1, 1, 1, 2), col=colors)
mean=80
sd=10
lb=60
ub=100
data <- seq(-4,4,length=100)*sd + mean
hx <- dnorm(data,mean,sd)
plot(data, hx, type="n", xlab="Temperature Values", ylab="",
main="Normal Distribution", axes=FALSE)
i <- data>= lb & data <= ub
lines(data, hx)
polygon(c(lb,data[i],ub), c(0,hx[i],0), col="red")
area <- pnorm(ub, mean, sd) - pnorm(lb, mean, sd)
result <- paste("P(",lb,"< Temp <",ub,") =",
signif(area, digits=3))
mtext(result,3)
axis(1, at=seq(40, 160, 20), pos=0)
x <- seq(from=-3, to=+3, length.out=100)
y <- dnorm(x)
plot(x, y, main="Standard Normal Distribution", type='l',
ylab="Density", xlab="Quantile")
abline(h=0)
# The body of the polygon follows the density curve where 1 <= z <= 2
region.x <- x[1 <= x & x <= 2]
region.y <- y[1 <= x & x <= 2]
# We add initial and final segments, which drop down to the Y axis
region.x <- c(region.x[1], region.x, tail(region.x,1))
region.y <- c(0, region.y, 0)
#call Polygon to plot the boundary of the region and fill it
polygon(region.x, region.y, density=10)
pnorm(27.4, mean=50, sd=20)
pnorm(27.4, 50, 20)
qnorm(0.95, mean=100, sd=15)
energy <- rnorm(100)
dens <- density(energy)
sum(dens$y)*diff(dens$x[1:2])
hist(energy,probability=TRUE) #Use the probability=TRUE option of hist or the function density() (or both)
lines(density(energy),col="red")
#probability for a discrete variabl
x <- sample(letters[1:4],1000,replace=TRUE)
prop.table(table(x))
x <- sort(rnorm(100,0,0.5))
h <- hist(x,plot=FALSE)
dens1 <-  h$counts/sum(h$counts)
dens2 <- dnorm(x,0,0.5)
hist(x,probability=TRUE,breaks="fd",ylim=c(0,1), xlim=c(-1.5,1.5))
lines(h$mids,dens1,col="red")
lines(x,dens2,col="darkgreen")
cdf <- cumsum(dens$y * diff(dens$x[1:2]))
cdf <- cdf / max(cdf) # to correct for the rounding errors
plot(dens$x,cdf,type="l")
mydata<-read.table(file = "mead_2013.txt", header=TRUE, sep = "")
head(mydata)
fit <- lm(ET ~ THigh + RelHum + SolarRad, data=mydata)
summary(fit) # show results
coefficients(fit) # model coefficients
confint(fit, level=0.95) # CIs for model parameters
fitted(fit) # predicted values
plot (fitted(fit))
residuals(fit) # residuals
anova(fit) # anova table
vcov(fit) # covariance matrix for model parameters
influence(fit) # regression diagnostics
data(sunspots)
sample.mean <- mean(sunspots)
sample.sd <- sd(sunspots)
n <- length(sunspots)
mu_0 <- 50
t.stat <- (sample.mean - mu_0)/(sample.sd/sqrt(n))
t.stat
p.value <- pnorm(-t.stat, 0, 1) + 1 - pnorm(t.stat, 0, 1)
p.value
##  H_A : mu greater than 51.25
p.value <- 1 - pnorm(t.stat, 0, 1)
p.value
##  H_A:  mu less than 51.25
p.value <- pnorm(t.stat, 0, 1)
p.value
##  We can use the t.test function when we are testing a hypothesis about a
t.test(xx1, xx2, alternative = "less", var.equal = TRUE)
